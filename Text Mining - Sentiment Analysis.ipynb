{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Just a bunch of packages \"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from time import time\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this Aggie Invent we only need to consider text data (description) so columns like NhtsaID, Make, Mode, etc are useless here.\n",
    "\"\"\"\n",
    "\n",
    "# Increase column width to let pandy read large text columns\n",
    "pd.set_option('max_colwidth', 32000)\n",
    "# Data of complaints\n",
    "df = pd.read_excel(\"HondaComplaints.xlsx\")\n",
    "sw = pd.read_excel(\"afinn_sentiment_words.xlsx\") # Sentiment words dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>NhtsaID</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>abs</th>\n",
       "      <th>cruise</th>\n",
       "      <th>crash</th>\n",
       "      <th>mph</th>\n",
       "      <th>mileage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONSUMER STATES FIRESTONE TIRE (NO SIZE) EXPERIENCED A LEAK IN THE SIDEWALL ON THE RIGHT FRONT TIRE, CONSUMER IS ANGRY DUE TO GETTING A RUN AROUND FROM HONDA DEALER AND FIRESTONE DEALER, CONSUMER ENDED UP HAVING TO BUY THE TIRE.</td>\n",
       "      <td>560001</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>CIVIC</td>\n",
       "      <td>2001</td>\n",
       "      <td>CA</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>31</td>\n",
       "      <td>85064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE VEHICLE EXPERIENCES EXCESSIVE VIBRATION OF THE FRONT END WHILE DRIVING 50-70 MPH.</td>\n",
       "      <td>561194</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>ACCORD</td>\n",
       "      <td>2001</td>\n",
       "      <td>CA</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>70</td>\n",
       "      <td>87186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONSUMER IS NOT HAPPY WITH THE DEALER DURING RECALL REPAIR, DEALER REFUSED RENTAL CAR, WHILE VEHICLE WAS BEING SERVICED.</td>\n",
       "      <td>562006</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>CIVIC</td>\n",
       "      <td>2001</td>\n",
       "      <td>WV</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>31</td>\n",
       "      <td>81110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONSUMER IS NOT HAPPY WITH THE DEALER DURING RECALL REPAIR, DEALER REFUSED A RENTAL CAR, WHILE VEHICLE IS BEING REPAIRED.</td>\n",
       "      <td>562066</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>CIVIC</td>\n",
       "      <td>2001</td>\n",
       "      <td>WV</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>31</td>\n",
       "      <td>81110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONSUMER STATES WHEN HE PROCEEDED TO BACK UP, THE VEHICLE ACCELERATED RAPIDLY CAUSING CONSUMER TO BACK INTO A CEMENT POLE, AFTER CRASHING, CONSUMER PUT VEHICLE INTO DRIVE AND IT ACCELERATED RAPIDLY, WHICH ALS CAUSED HIM TO REAR END A PARKED VEHICLE.</td>\n",
       "      <td>562091</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>ACCORD</td>\n",
       "      <td>2001</td>\n",
       "      <td>PA</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>24</td>\n",
       "      <td>96792.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                 description  \\\n",
       "0                       CONSUMER STATES FIRESTONE TIRE (NO SIZE) EXPERIENCED A LEAK IN THE SIDEWALL ON THE RIGHT FRONT TIRE, CONSUMER IS ANGRY DUE TO GETTING A RUN AROUND FROM HONDA DEALER AND FIRESTONE DEALER, CONSUMER ENDED UP HAVING TO BUY THE TIRE.   \n",
       "1                                                                                                                                                                      THE VEHICLE EXPERIENCES EXCESSIVE VIBRATION OF THE FRONT END WHILE DRIVING 50-70 MPH.   \n",
       "2                                                                                                                                   CONSUMER IS NOT HAPPY WITH THE DEALER DURING RECALL REPAIR, DEALER REFUSED RENTAL CAR, WHILE VEHICLE WAS BEING SERVICED.   \n",
       "3                                                                                                                                  CONSUMER IS NOT HAPPY WITH THE DEALER DURING RECALL REPAIR, DEALER REFUSED A RENTAL CAR, WHILE VEHICLE IS BEING REPAIRED.   \n",
       "4  CONSUMER STATES WHEN HE PROCEEDED TO BACK UP, THE VEHICLE ACCELERATED RAPIDLY CAUSING CONSUMER TO BACK INTO A CEMENT POLE, AFTER CRASHING, CONSUMER PUT VEHICLE INTO DRIVE AND IT ACCELERATED RAPIDLY, WHICH ALS CAUSED HIM TO REAR END A PARKED VEHICLE.   \n",
       "\n",
       "   NhtsaID   Make   Model  Year State abs cruise crash  mph  mileage  \n",
       "0   560001  HONDA   CIVIC  2001    CA   N      N     N   31  85064.0  \n",
       "1   561194  HONDA  ACCORD  2001    CA   N      N     N   70  87186.0  \n",
       "2   562006  HONDA   CIVIC  2001    WV   N      N     N   31  81110.0  \n",
       "3   562066  HONDA   CIVIC  2001    WV   N      N     N   31  81110.0  \n",
       "4   562091  HONDA  ACCORD  2001    PA   N      N     N   24  96792.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brief view of our main dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandons</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abducted</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abduction</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  score\n",
       "0    abandon   -2.0\n",
       "1  abandoned   -2.0\n",
       "2   abandons   -2.0\n",
       "3   abducted   -2.0\n",
       "4  abduction   -2.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Brief view of sentiment dictionary\n",
    "sw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "*Function Design*\n",
    "\n",
    "\"\"\"\n",
    "def my_analyzer(s):\n",
    "    # Synonym List\n",
    "    syns = {'veh': 'vehicle', 'car': 'vehicle', 'chev':'cheverolet', \\\n",
    "              'chevy':'cheverolet', 'air bag': 'airbag', \\\n",
    "              'seat belt':'seatbelt', \"n't\":'not', 'to30':'to 30', \\\n",
    "              'wont':'would not', 'cant':'can not', 'cannot':'can not', \\\n",
    "              'couldnt':'could not', 'shouldnt':'should not', \\\n",
    "              'wouldnt':'would not', 'straightforward': 'straight forward' }\n",
    "    \n",
    "    # Preprocess String s\n",
    "    s = s.lower()\n",
    "    # Replace special characters with spaces\n",
    "    s = s.replace('-', ' ')\n",
    "    s = s.replace('_', ' ')\n",
    "    s = s.replace(',', '. ')\n",
    "    # Replace not contraction with not\n",
    "    s = s.replace(\"'nt\", \" not\")\n",
    "    s = s.replace(\"n't\", \" not\")\n",
    "    # Tokenize \n",
    "    tokens = word_tokenize(s)\n",
    "    #tokens = [word.replace(',','') for word in tokens ]\n",
    "    tokens = [word for word in tokens if ('*' not in word) and \\\n",
    "              (\"''\" != word) and (\"``\" != word) and \\\n",
    "              (word!='description') and (word !='dtype') \\\n",
    "              and (word != 'object') and (word!=\"'s\")]\n",
    "    \n",
    "    # Map synonyms\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] in syns:\n",
    "            tokens[i] = syns[tokens[i]]\n",
    "            \n",
    "    # Remove stop words\n",
    "    punctuation = list(string.punctuation)+['..', '...']\n",
    "    pronouns = ['i', 'he', 'she', 'it', 'him', 'they', 'we', 'us', 'them']\n",
    "    others   = [\"'d\", \"co\", \"ed\", \"put\", \"say\", \"get\", \"can\", \"become\",\\\n",
    "                \"los\", \"sta\", \"la\", \"use\", \"iii\", \"else\",\"honda\",\"vehicle\"\\\n",
    "                \"dealer\",\"problem\"]\n",
    "    stop = stopwords.words('english') + punctuation + pronouns + others\n",
    "    filtered_terms = [word for word in tokens if (word not in stop) and \\\n",
    "                  (len(word)>1) and (not word.replace('.','',1).isnumeric()) \\\n",
    "                  and (not word.replace(\"'\",'',2).isnumeric())]\n",
    "    \n",
    "    # Lemmatization & Stemming - Stemming with WordNet POS\n",
    "    # Since lemmatization requires POS need to set POS\n",
    "    tagged_words = pos_tag(filtered_terms, lang='eng')\n",
    "    # Stemming with for terms without WordNet POS\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    wn_tags = {'N':wn.NOUN, 'J':wn.ADJ, 'V':wn.VERB, 'R':wn.ADV}\n",
    "    wnl = WordNetLemmatizer()\n",
    "    stemmed_tokens = []\n",
    "    for tagged_token in tagged_words:\n",
    "        term = tagged_token[0]\n",
    "        pos  = tagged_token[1]\n",
    "        pos  = pos[0]\n",
    "        try:\n",
    "            pos   = wn_tags[pos]\n",
    "            stemmed_tokens.append(wnl.lemmatize(term, pos=pos))\n",
    "        except:\n",
    "            stemmed_tokens.append(stemmer.stem(term))\n",
    "    return stemmed_tokens\n",
    "\n",
    "def my_preprocessor(s):\n",
    "    #Preprocess String s\n",
    "    s=s.lower()\n",
    "    #Replace special characters with spaces\n",
    "    s=s.replace('-',' ')\n",
    "    s=s.replace('_',' ')\n",
    "    s=s.replace(',','. ')\n",
    "    #Replace not contraction with not\n",
    "    s=s.replace(\"'nt\", \" not\")\n",
    "    s=s.replace(\"n't\", \" not\")\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** Sentiment Analysis ****\n",
      "abandon -2.0\n",
      "abandoned -2.0\n",
      "abandons -2.0\n",
      "abducted -2.0\n",
      "abduction -2.0\n",
      "abductions -2.0\n",
      "abhor -3.0\n",
      "abhorred -3.0\n",
      "abhorrent -3.0\n",
      "abhors -3.0\n",
      "abilities 2.0\n",
      "Number of Reviews.....  5330\n",
      "Number of Terms.......132050\n",
      "\n",
      "Corpus Average Sentiment:-1.08 \n",
      "\n",
      "Most Negative Reviews with 4 or more Sentiment Words:\n",
      "   Description  878 Sentiment is -2.75\n",
      "   Description 1231 Sentiment is -2.75\n",
      "   Description 2065 Sentiment is -2.75\n",
      "   Description 2778 Sentiment is -2.75\n",
      "   Description 3901 Sentiment is -2.75\n",
      "   Description 4360 Sentiment is -2.75\n",
      "\n",
      "Most Positive Reviews with 4 or more Sentiment Words:\n",
      "    Descrption 4588 Sentiment is  1.89\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Sentiment Analysis \"\"\"\n",
    "print(\"\\n**** Sentiment Analysis ****\")\n",
    "\n",
    "sentiment_dic = {}\n",
    "for i in range(len(sw)): \n",
    "    sentiment_dic[sw.iloc[i][0]] = sw.iloc[i][1]\n",
    "n = 0\n",
    "for k,v in sentiment_dic.items(): \n",
    "    n += 1\n",
    "    print(k, v) \n",
    "    if n>10:\n",
    "        break\n",
    "\"\"\" Create Term-Frequency Matrix for Sentiment Analysis \"\"\"\n",
    "cv = CountVectorizer(max_df=1.0,min_df=1, max_features=None,\\\n",
    "                     preprocessor=my_preprocessor, ngram_range=(1,2))\n",
    "tf = cv.fit_transform(df['description'])\n",
    "s_terms = cv.get_feature_names()\n",
    "n_reviews = tf.shape[0]\n",
    "n_terms = tf.shape[1]\n",
    "print('{:.<22s}{:>6d}'.format(\"Number of Reviews\",n_reviews)) \n",
    "print('{:.<22s}{:>6d}'.format(\"Number of Terms\",n_terms))\n",
    "\n",
    "\"\"\" Calculate Sentiment for each review \"\"\"\n",
    "min_sentiment = +5\n",
    "max_sentiment = -5 \n",
    "avg_sentiment, min, max = 0,0,0\n",
    "min_list, max_list = [],[] \n",
    "sentiment_score = [0]*n_reviews \n",
    "for i in range(n_reviews):\n",
    "    n_sw = 0\n",
    "    term_list = tf[i].nonzero()[1] \n",
    "    if len(term_list)>0:\n",
    "        for t in np.nditer(term_list):\n",
    "            score = sentiment_dic.get(s_terms[t]) \n",
    "            if score != None:\n",
    "                sentiment_score[i] += score * tf[i,t] \n",
    "                n_sw += tf[i,t]\n",
    "    if n_sw>0:\n",
    "        sentiment_score[i] = sentiment_score[i]/n_sw \n",
    "    if sentiment_score[i]==max_sentiment and n_sw>3:\n",
    "        max_list.append(i)\n",
    "    if sentiment_score[i]>max_sentiment and n_sw>3: \n",
    "        max_sentiment=sentiment_score[i]\n",
    "        max = i \n",
    "        max_list = [i]\n",
    "    if sentiment_score[i]==min_sentiment and n_sw>3: \n",
    "        min_list.append(i)\n",
    "    if sentiment_score[i]<min_sentiment and n_sw>3: \n",
    "        min_sentiment=sentiment_score[i]\n",
    "        min = i \n",
    "        min_list = [i]\n",
    "    avg_sentiment += sentiment_score[i] \n",
    "avg_sentiment = avg_sentiment/n_reviews\n",
    "print(\"\\nCorpus Average Sentiment:{:>5.2f} \".format(avg_sentiment)) \n",
    "print(\"\\nMost Negative Reviews with 4 or more Sentiment Words:\")\n",
    "for i in range(len(min_list)): \n",
    "    print(\"{:<s}{:>5d}{:<s}{:>5.2f}\".format(\"   Description\", min_list[i],\\\n",
    "          \" Sentiment is \",min_sentiment))\n",
    "print(\"\\nMost Positive Reviews with 4 or more Sentiment Words:\") \n",
    "for i in range(len(max_list)):\n",
    "    print(\"{:<s}{:>5d}{:<s}{:>5.2f}\".format(\"    Descrption\",max_list[i],\\\n",
    "          \" Sentiment is \",max_sentiment))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
