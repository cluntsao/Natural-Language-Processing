{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "wn_tags = {'N':wn.NOUN, 'J':wn.ADJ, 'V':wn.VERB, 'R':wn.ADV}\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "punctuation = list(string.punctuation) + ['..', '...']\n",
    "pronouns = ['i', 'he', 'she', 'it', 'him', 'they', 'we', 'us', 'them']\n",
    "extensions = ['tr', 'ion', 'tl']\n",
    "stop = stopwords.words('english') + punctuation + pronouns + extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('GMC_Complaints.xlsx', usecols = [1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2734 entries, 0 to 2733\n",
      "Data columns (total 7 columns):\n",
      "Year           2734 non-null int64\n",
      "make           2734 non-null object\n",
      "model          2734 non-null object\n",
      "description    2734 non-null object\n",
      "crashed        2734 non-null object\n",
      "abs            2716 non-null object\n",
      "mileage        2315 non-null float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 149.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>description</th>\n",
       "      <th>crashed</th>\n",
       "      <th>abs</th>\n",
       "      <th>mileage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>SATURN</td>\n",
       "      <td>ION</td>\n",
       "      <td>WHILE TRAVELING ON THE HIGHWAY AND WITHOUT PRI...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>SATURN</td>\n",
       "      <td>ION</td>\n",
       "      <td>WHILE DRIVING TRANSMISSION DOES NOT ENGAGE PRO...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>SATURN</td>\n",
       "      <td>ION</td>\n",
       "      <td>IN A PANIC SITUATION, THE OWNER WAS UNABLE TO ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>SATURN</td>\n",
       "      <td>ION</td>\n",
       "      <td>THE TWO SATURN 2003 IONS I HAVE DRIVEN  (INCLU...</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>10600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>SATURN</td>\n",
       "      <td>ION</td>\n",
       "      <td>I BOUGHT A ION QUAD COUPE IN JULY OF THIS YEAR...</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>6365.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year    make model                                        description  \\\n",
       "0  2003  SATURN   ION  WHILE TRAVELING ON THE HIGHWAY AND WITHOUT PRI...   \n",
       "1  2003  SATURN   ION  WHILE DRIVING TRANSMISSION DOES NOT ENGAGE PRO...   \n",
       "2  2003  SATURN   ION  IN A PANIC SITUATION, THE OWNER WAS UNABLE TO ...   \n",
       "3  2003  SATURN   ION  THE TWO SATURN 2003 IONS I HAVE DRIVEN  (INCLU...   \n",
       "4  2003  SATURN   ION  I BOUGHT A ION QUAD COUPE IN JULY OF THIS YEAR...   \n",
       "\n",
       "  crashed abs  mileage  \n",
       "0       N   N      NaN  \n",
       "1       N   N      NaN  \n",
       "2       N   N    500.0  \n",
       "3       N   Y  10600.0  \n",
       "4       N   Y   6365.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year {2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011}\n",
      "make {'PONTIAC', 'SATURN', 'CHEVROLET'}\n",
      "model {'SOLSTICE', 'COBALT', 'G5', 'SKY', 'ION', 'HHR'}\n",
      "abs {nan, 'Y', 'N'}\n"
     ]
    }
   ],
   "source": [
    "for col in ['Year', 'make', 'model', 'abs']:\n",
    "    print(col, set(df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(df):\n",
    "    df.crashed = df.crashed.map({'N' : 0, 'Y' : 1})\n",
    "    df.mileage.fillna(df.mileage.mean(), inplace=True)\n",
    "    \n",
    "    for col in ['Year', 'make', 'model', 'abs']:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    X = pd.get_dummies(df.drop(['crashed', 'description'], 1))\n",
    "    \n",
    "    y = df.crashed\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2734, 21) (2734,)\n"
     ]
    }
   ],
   "source": [
    "X, y = prep(df)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WHILE TRAVELING ON THE HIGHWAY AND WITHOUT PRIOR WARNING SEAT BELT RETRACTOR FELL APART.  *AK  THE BOLT THAT CONNECTS THE WEBBING TO THE FLOOR WAS NOT FULLY SCREWED IN AT THE PLANT.  THE BOLT BACKED OUT AND THE LOWER PORTION OF THE SEATBELT WEBBING BECAME UNATTACHED.  THIS IS NOT A BUCKLE ISSUE OR A RETRACTOR ISSUE.  MANUFACTURING DEFECT FROM THE PLANT BECAUSE THE BOLT WAS NOT FULLY TORQUED.  DEALER FIXED BY TIGHTENING THE BOLT.  CW'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WHEN THE TEMPERATURE IS 32 DEGREES OR LESS AND THE ENGINE IS NOT RUNNING I ATTEMPT TO START MY CAR AND IT WILL NOT START. THE IGNITION SWITCH CLICKS AND THEN THE CAR STALLS. THE SECURITY SYSTEM KICKS IN AND THE SECURITY LIGHT COMES ON AND THEN THE ODOMETER SCREEN READS \"SERVICE VEHICLE SOON\". THE CAR WILL NOT START FOR ABOUT 8 TO 10 MINUTES. AFTER 8 TO 10 MINUTES THE LIGHT STOPS BLINKING AND THE SERVICE VEHICLE GOES OFF AND THEN THE CAR STARTS. THIS HAS HAPPENED SEVERAL TIMES SINCE THEN AND IT OCCURS ALL DIFFERENT TIMES OF THE DAYS. AS I READ ON THE INTERNET THERE HAVE BEEN SEVERAL PEOPLE WITH THE SAME PROBLEMS. THIS IS GOING TO COST ME APPROXIMATELY $200.00 TO FIX.   *TR'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TL*THE CONTACT OWNS A 2005 CHEVROLET COBALT.  WHILE DRIVING 70 MPH ON THE FREEWAY, THE \"REDUCE ENGINE SPEED\" INDICATOR ILLUMINATED ON THE INSTRUMENT PANEL.  THE VEHICLE SHIFTED INTO LOW GEAR AND THE CONTACT COULD NOT ACCELERATE BEYOND 40 MPH, WHICH SHE CONSIDERED VERY DANGEROUS ON A HIGHWAY ALLOWING 70 MPH SPEEDS.  THE VEHICLE BEGAN OPERATING NORMALLY.  PRIOR TO THE FAILURE, SHE NOTICED THAT THE VEHICLE BEGAN STALLING WHEN SHE WOULD SLOW DOWN AT TRAFFIC LIGHTS OR STOP SIGNS.  OCCASIONALLY, THE CONTACT WOULD HAVE TO SHIFT THE VEHICLE INTO NEUTRAL SO THAT IT COULD PERFORM CORRECTLY.  ON THREE OCCASIONS, A MECHANIC STATED THAT MULTIPLE CODES WERE PRESENT AFTER DIAGNOSING THE VEHICLE.  THE MANUFACTURER STATED THAT THERE WAS NO RELEVANT RECALL TO-DATE.  THE CURRENT MILEAGE WAS APPROXIMATELY 82,000 AND FAILURE MILEAGE WAS APPROXIMATELY 80,000.   UPDATED 4/23/09 *CN  UPDATED 04/27/09*JB'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description[265]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(s):\n",
    "    return re.findall(r'[a-z]+', s)\n",
    "\n",
    "def analyzer(s):\n",
    "    s = s.lower()\n",
    "    \n",
    "    tokens = tokenizer(s)\n",
    "    \n",
    "    #Remove Stop Words\n",
    "    tokens = [word for word in tokens if word not in stop]\n",
    "    \n",
    "    #Lemmatization & Stemming - Stemming with WordNet POS\n",
    "    tagged_words = pos_tag(tokens, lang='eng')\n",
    "    \n",
    "    stemmed_tokens = []\n",
    "    for tagged_word in tagged_words:\n",
    "        term = tagged_word[0]\n",
    "        pos = tagged_word[1]\n",
    "        pos = pos[0]\n",
    "        try:\n",
    "            pos = wn_tags[pos]\n",
    "            stemmed_tokens.append(wnl.lemmatize(term, pos=pos))\n",
    "        except:\n",
    "            stemmed_tokens.append(stemmer.stem(term))\n",
    "    \n",
    "    return list(set(stemmed_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup simple constants\n",
    "n_docs     = len(df)\n",
    "n_samples  = n_docs\n",
    "m_features = 100\n",
    "s_words    = 'english'\n",
    "ngram = (1,2)\n",
    "\n",
    "n_topics        = 8\n",
    "max_iter        =  5\n",
    "learning_offset = 20.\n",
    "learning_method = 'online'\n",
    "\n",
    "description = df.description.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF_IDF Vectorizer Parameters\n",
      " TfidfVectorizer(analyzer=<function analyzer at 0x000001280DBD49D8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=0.95,\n",
      "        max_features=100, min_df=2, ngram_range=(1, 2), norm='l2',\n",
      "        preprocessor=None, smooth_idf=True, stop_words=None,\n",
      "        strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None) \n",
      "\n",
      "Number of Reviews.....  2734\n",
      "Number of Terms.......   100\n",
      "\n",
      "Topics Identified using LDA with TF_IDF\n",
      "Topic #0: saturn problem cause light turn steer two power lock car vehicle wheel make also drive\n",
      "\n",
      "Topic #1: accident car gm recall fuel problem could one part find still time get say issue\n",
      "\n",
      "Topic #2: ignition key switch start car saturn turn problem lock replace recall would engine get time\n",
      "\n",
      "Topic #3: front hit side driver brake deploy right leave mph wheel car crash stop air bag\n",
      "\n",
      "Topic #4: power steer go car drive turn steering come chevy cobalt light lose work road back\n",
      "\n",
      "Topic #5: car problem go fix power steer mile recall chevy get issue say dealership tell need\n",
      "\n",
      "Topic #6: own mileage contact failure state manufacturer chevrolet vehicle current repair dealer mph cobalt drive approximately\n",
      "\n",
      "Topic #7: air bag deploy report crash anoth accident fail vehicle mph cause lose saturn car state\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(max_df=0.95, \n",
    "                             min_df=2, \n",
    "                             max_features=m_features,\n",
    "                             analyzer=analyzer, \n",
    "                             ngram_range=ngram)\n",
    "\n",
    "tf_idf = tfidf_vect.fit_transform(description)\n",
    "print(\"\\nTF_IDF Vectorizer Parameters\\n\", tfidf_vect, \"\\n\")\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, \n",
    "                                max_iter=max_iter,\n",
    "                                learning_method=learning_method, \n",
    "                                learning_offset=learning_offset, \n",
    "                                random_state=12345)\n",
    "\n",
    "prob_matrix = lda.fit_transform(tf_idf)\n",
    "\n",
    "print('{:.<22s}{:>6d}'.format(\"Number of Reviews\", tf_idf.shape[0]))\n",
    "print('{:.<22s}{:>6d}'.format(\"Number of Terms\",     tf_idf.shape[1]))\n",
    "print(\"\\nTopics Identified using LDA with TF_IDF\")\n",
    "tf_features = tfidf_vect.get_feature_names()\n",
    "max_words = 15\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([tf_features[i]\n",
    "                             for i in topic.argsort()[:-max_words - 1:-1]])\n",
    "        print(message)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, pd.get_dummies(pd.Series(np.argmax(prob_matrix, axis = 1)))], 1)\n",
    "X['cluster_prob'] = np.max(prob_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    829\n",
       "4    560\n",
       "5    485\n",
       "1    328\n",
       "2    267\n",
       "3    211\n",
       "7     36\n",
       "0     18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.argmax(prob_matrix, axis=1)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1913, 30) (821, 30) (1913,) (821,)\n"
     ]
    }
   ],
   "source": [
    "X, y = shuffle(X, y, random_state = 12345)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 12345)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([1.00000e-03, 3.72759e-03, 1.38950e-02, 5.17947e-02, 1.93070e-01,\n",
       "       7.19686e-01, 2.68270e+00, 1.00000e+01, 3.72759e+01, 1.38950e+02,\n",
       "       5.17947e+02, 1.93070e+03, 7.19686e+03, 2.68270e+04, 1.00000e+05])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'C' : np.logspace(-3, 5, 15)}\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "log_cv = GridSearchCV(log_model, param_grid=params, scoring='accuracy', cv = 10)\n",
    "\n",
    "log_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.70      0.82       821\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.70      0.82       821\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.0001)\n",
    "model.fit(X_train, y_train)\n",
    "print(classification_report(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00391254, 0.00221255, 0.00230894, 0.00232465, 0.00241823,\n",
       "        0.00242822, 0.00201695, 0.00202203, 0.00221887, 0.00242474,\n",
       "        0.00233266, 0.00222447, 0.00241992, 0.00202694, 0.00212975]),\n",
       " 'mean_score_time': array([0.0003978 , 0.00029941, 0.00050287, 0.00019789, 0.00019875,\n",
       "        0.00029576, 0.00049219, 0.00049431, 0.00020204, 0.00039594,\n",
       "        0.00019634, 0.00019417, 0.00029273, 0.00048862, 0.00029554]),\n",
       " 'mean_test_score': array([0.71981181, 0.71981181, 0.71981181, 0.71981181, 0.71981181,\n",
       "        0.71981181, 0.71981181, 0.71981181, 0.71981181, 0.71981181,\n",
       "        0.71981181, 0.71981181, 0.71981181, 0.71981181, 0.71981181]),\n",
       " 'mean_train_score': array([0.71981188, 0.71981188, 0.71981188, 0.71981188, 0.71981188,\n",
       "        0.71981188, 0.71981188, 0.71981188, 0.71981188, 0.71981188,\n",
       "        0.71981188, 0.71981188, 0.71981188, 0.71981188, 0.71981188]),\n",
       " 'param_C': masked_array(data=[0.001, 0.003727593720314938, 0.013894954943731374,\n",
       "                    0.0517947467923121, 0.19306977288832497,\n",
       "                    0.7196856730011514, 2.6826957952797246, 10.0,\n",
       "                    37.27593720314938, 138.9495494373136,\n",
       "                    517.9474679231203, 1930.6977288832495,\n",
       "                    7196.856730011514, 26826.95795279722, 100000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.001},\n",
       "  {'C': 0.003727593720314938},\n",
       "  {'C': 0.013894954943731374},\n",
       "  {'C': 0.0517947467923121},\n",
       "  {'C': 0.19306977288832497},\n",
       "  {'C': 0.7196856730011514},\n",
       "  {'C': 2.6826957952797246},\n",
       "  {'C': 10.0},\n",
       "  {'C': 37.27593720314938},\n",
       "  {'C': 138.9495494373136},\n",
       "  {'C': 517.9474679231203},\n",
       "  {'C': 1930.6977288832495},\n",
       "  {'C': 7196.856730011514},\n",
       "  {'C': 26826.95795279722},\n",
       "  {'C': 100000.0}],\n",
       " 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'split0_test_score': array([0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875,\n",
       "        0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875,\n",
       "        0.71875]),\n",
       " 'split0_train_score': array([0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027,\n",
       "        0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027,\n",
       "        0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027]),\n",
       " 'split1_test_score': array([0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875,\n",
       "        0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875,\n",
       "        0.71875]),\n",
       " 'split1_train_score': array([0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027,\n",
       "        0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027,\n",
       "        0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027]),\n",
       " 'split2_test_score': array([0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875,\n",
       "        0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875,\n",
       "        0.71875]),\n",
       " 'split2_train_score': array([0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027,\n",
       "        0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027,\n",
       "        0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027]),\n",
       " 'split3_test_score': array([0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875,\n",
       "        0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875,\n",
       "        0.71875]),\n",
       " 'split3_train_score': array([0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027,\n",
       "        0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027,\n",
       "        0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027]),\n",
       " 'split4_test_score': array([0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875,\n",
       "        0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875,\n",
       "        0.71875]),\n",
       " 'split4_train_score': array([0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027,\n",
       "        0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027,\n",
       "        0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027]),\n",
       " 'split5_test_score': array([0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875,\n",
       "        0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875,\n",
       "        0.71875]),\n",
       " 'split5_train_score': array([0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027,\n",
       "        0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027,\n",
       "        0.71993027, 0.71993027, 0.71993027, 0.71993027, 0.71993027]),\n",
       " 'split6_test_score': array([0.72251309, 0.72251309, 0.72251309, 0.72251309, 0.72251309,\n",
       "        0.72251309, 0.72251309, 0.72251309, 0.72251309, 0.72251309,\n",
       "        0.72251309, 0.72251309, 0.72251309, 0.72251309, 0.72251309]),\n",
       " 'split6_train_score': array([0.7195122, 0.7195122, 0.7195122, 0.7195122, 0.7195122, 0.7195122,\n",
       "        0.7195122, 0.7195122, 0.7195122, 0.7195122, 0.7195122, 0.7195122,\n",
       "        0.7195122, 0.7195122, 0.7195122]),\n",
       " 'split7_test_score': array([0.72105263, 0.72105263, 0.72105263, 0.72105263, 0.72105263,\n",
       "        0.72105263, 0.72105263, 0.72105263, 0.72105263, 0.72105263,\n",
       "        0.72105263, 0.72105263, 0.72105263, 0.72105263, 0.72105263]),\n",
       " 'split7_train_score': array([0.71967499, 0.71967499, 0.71967499, 0.71967499, 0.71967499,\n",
       "        0.71967499, 0.71967499, 0.71967499, 0.71967499, 0.71967499,\n",
       "        0.71967499, 0.71967499, 0.71967499, 0.71967499, 0.71967499]),\n",
       " 'split8_test_score': array([0.72105263, 0.72105263, 0.72105263, 0.72105263, 0.72105263,\n",
       "        0.72105263, 0.72105263, 0.72105263, 0.72105263, 0.72105263,\n",
       "        0.72105263, 0.72105263, 0.72105263, 0.72105263, 0.72105263]),\n",
       " 'split8_train_score': array([0.71967499, 0.71967499, 0.71967499, 0.71967499, 0.71967499,\n",
       "        0.71967499, 0.71967499, 0.71967499, 0.71967499, 0.71967499,\n",
       "        0.71967499, 0.71967499, 0.71967499, 0.71967499, 0.71967499]),\n",
       " 'split9_test_score': array([0.72105263, 0.72105263, 0.72105263, 0.72105263, 0.72105263,\n",
       "        0.72105263, 0.72105263, 0.72105263, 0.72105263, 0.72105263,\n",
       "        0.72105263, 0.72105263, 0.72105263, 0.72105263, 0.72105263]),\n",
       " 'split9_train_score': array([0.71967499, 0.71967499, 0.71967499, 0.71967499, 0.71967499,\n",
       "        0.71967499, 0.71967499, 0.71967499, 0.71967499, 0.71967499,\n",
       "        0.71967499, 0.71967499, 0.71967499, 0.71967499, 0.71967499]),\n",
       " 'std_fit_time': array([5.07199840e-03, 4.00244631e-04, 4.51611554e-04, 4.60795049e-04,\n",
       "        4.92844811e-04, 5.00917730e-04, 2.19777578e-05, 2.89271603e-05,\n",
       "        4.01761498e-04, 4.96472083e-04, 4.86438065e-04, 4.01020652e-04,\n",
       "        6.73254322e-04, 2.19788311e-05, 2.88128568e-04]),\n",
       " 'std_score_time': array([0.00048728, 0.00045738, 0.00050302, 0.00039578, 0.0003975 ,\n",
       "        0.00045178, 0.00049243, 0.00049434, 0.00040409, 0.00048495,\n",
       "        0.00039268, 0.00038834, 0.00044724, 0.00048876, 0.00045145]),\n",
       " 'std_test_score': array([0.0013661, 0.0013661, 0.0013661, 0.0013661, 0.0013661, 0.0013661,\n",
       "        0.0013661, 0.0013661, 0.0013661, 0.0013661, 0.0013661, 0.0013661,\n",
       "        0.0013661, 0.0013661, 0.0013661]),\n",
       " 'std_train_score': array([0.0001517, 0.0001517, 0.0001517, 0.0001517, 0.0001517, 0.0001517,\n",
       "        0.0001517, 0.0001517, 0.0001517, 0.0001517, 0.0001517, 0.0001517,\n",
       "        0.0001517, 0.0001517, 0.0001517])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.86       623\n",
      "          1       0.00      0.00      0.00       198\n",
      "\n",
      "avg / total       0.58      0.76      0.65       821\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "pred = log_cv.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
